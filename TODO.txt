1. Make sure OpenAI env name is valid
2. Make sure action selection strategy is valid e.g. vae => random action

3. Allows the user to play the environment to get a feel of how it works (on double click)

4. Allow the training of the agents on the environments (locally and on the cluster)

5. Display the status of each training job (pending in gray, crashed in red, successful in green, running in orange):
5.a. Display the time it has been running for / the time it took before it crashes / the time it took for training the agent / etc ...
5.b. Display the hardware it was run on, i.e., pascal, volta, etc ...
5.c. Allow the user to display the config of the job

6. Allow the user to analyse the agents policies by saving every 100K training iteration a trial made by the agent
7. Allow the user to analyse the representation learned by the agents by showing examples of reconstruction of sequences of images
8. Allow the user to look at the amount of rewards gathered by the agent
9. Allow the user to look at the variational free energy of the agent

10. (bonus) Allow the user to compute the representational similarities between the layers of two sets of agents
11. (bonus) Allow the user to visualise the variance of the latent spaces for different agents
12. (bonus) Allow the user to visualise the actions taken by the agent as training progresses and the entropy of the prior over actions
13. (bonus) Allow the agents and environments to be grouped within subdirectories
