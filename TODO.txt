0. Clean up the code

1. Implement NewAgentFrame
2. Implement NewEnvironmentFrame
3. Display agent specifications on double click
4. Display environments specifications on double click + allows the user to play the environment to get a feel of how it works

5. Allow the training of the agents on the environments (locally and on the cluster)

6. Display the status of each training job (pending in gray, crashed in red, successful in green, running in orange):
6.a. Display the time it has been running for / the time it took before it crashes / the time it took for training the agent / etc ...
6.b. Display the hardware it was run on, i.e., pascal, volta, etc ...
6.c. Allow the user to display the config of the job

7. Allow the user to analyse the agents policies by saving every 100K training iteration a trial made by the agent
8. Allow the user to analyse the representation learned by the agents by showing examples of reconstruction of sequences of images
9. Allow the user to look at the amount of rewards gathered by the agent
10. Allow the user to look at the variational free energy of the agent

11. (bonus) Allow the user to compute the representational similarities between the layers of two sets of agents
12. (bonus) Allow the user to visualise the variance of the latent spaces for different agents
13. (bonus) Allow the user to visualise the actions taken by the agent as training progresses and the entropy of the prior over actions
14. (bonus) Allows the agents and environments to be grouped within subdirectories
