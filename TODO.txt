1. Allow the training of the agents on the environments (locally and on the cluster)
1.a. Make sure the agent and environment are implemented
1.a. Make sure ssh server training works

2. Display the status of each training job (pending in gray, crashed in red, successful in green, running in orange):
2.a. Display the time it has been running for / the time it took before it crashes / the time it took for training the agent / etc ...
2.b. Display the hardware it was run on, i.e., pascal, volta, etc ...
2.c. Display the host it was run on, i.e., local computer, hydra cluster, etc ...
2.d. Display the agent and environment of the job

3. Allow the user to analyse the agents policies by saving every 10K training iteration a trial made by the agent (the user must be able to choose the time granularity)
4. Allow the user to analyse the representation learned by the agents by showing examples of reconstruction of sequences of images
5. Allow the user to look at the amount of rewards gathered by the agent
6. Allow the user to look at the variational free energy of the agent

7. (bonus) Allow the user to compute the representational similarities between the layers of two sets of agents
8. (bonus) Allow the user to visualise the variance of the latent spaces for different agents
9. (bonus) Allow the user to visualise the actions taken by the agent as training progresses and the entropy of the prior over actions
10. (bonus) Allow the agents and environments to be grouped within subdirectories
